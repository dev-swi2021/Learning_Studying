## 추천 시스템 입문 강의 내용 정리 및 공부  
#### 참고
- T academy (https://tacademy.skplanet.com/)  
- Recommender System KR(https://www.facebook.com/groups/2611614312273351)  
- 발표 연사자 github (https://github.com/choco9966/T-academy-Recommendation)  
- 케글 (https://www.kaggle.com/chocozzz/t-academy-recommendation2)  
- 참고 사이트 (https://bab2min.tistory.com/566)

#### 사용 데이터
- https://www.kaggle.com/zygmunt/goodbooks-10k  

### [1강] 추천 시스템 이해  

사용자에게 흥미로울 만한 상품을 제안하는 도구 기술  
-> 목표 : 어떤 사용자에게 어떤 상품을 어떻게 추천할지에  
인터넷 발전 --> 롱테일의 법칙 > 파레토의 법칙  

1. 연관분석  
-> 상품과 상품사이에 어떤 연관이 있는지 찾는 알고리즘  
1) 얼마나 같이 구매가 되는가  
2) A를 구매한 사람이 B를 구매하는가?  
평가지표 : support(지지도), lift(향상도), confidence(신뢰도)  
상품이 많을 경우 경우의수가 너무 많아짐(메모리 증가)  

2. Apriori 알고리즘  
-> 아이템셋의 증가를 줄이기 위한 방법  
진행방법  
- 단일항목집단에서 최소 지지도 이상의 항목을 선택  
- k개의 집단을 계속 만들어서 반복  
장점: 이해할 수 있음(결과에 대해서)  
단점: 연산량 많음, 속도 느림(인과관계 해석의 한계)  

3. FP-Growth 알고리즘  
Apriori 알고리즘 속도 한계 해결  
설계가 어려움, 지지도 계산이 FP-Tree를 만들고 나서 가능함  

### [2강] 컨텐츠 기반 모델 (TF-IDF 설명)  
아이템을 벡터 형태로 표현 -> 벡터들간의 유사도를 계산 후 추출  

유사도 함수  
-유클리디안 유사도(문서간의 유사도를 계산)  
= 1 / (유클리디안 거리 + 1e-05(=eps))  
계산하기 쉽지만, 두 아이템의 분포가 다르거나 범위가 다른 경우 상관성 놓치기 쉬움  

- 코사인 유사도  
문서간의 유사도를 계산  
theta값을 가지고 유사도를 계산  
벡터의 크기가 중요하지 않은 경우에 많이 사용  

- 피어슨 유사도  
- 자카드 유사도(집합간의 결합관련)  

-> 도메인에 따른 유사도 계산을 해야함  

알고리즘: TF-IDF(텍스트 기반일 경우)  
TF-IDF를 사용하는 이유  
-> 의미없지만 많이 반복되는 단어들을 페널티를 주어 의미있는 단어들이 부각되게 하는 법  
직관적인 해석이 가능하지만 sparse 행렬이 될 확률이 많다. **(메모리 많이 잡아먹음)**  

### [3강] 컨텐츠 기반 모델 (Word2Vec 설명)
통계기반의 방법 단점  
-> 대규모 말뭉치는 메모리상의 문제가 발생(sparse형태이기 때문)  

해결책
Word2Vec - 단어간 유사도를 반영하여 단어를 벡터로 변환 (성능 : skip-gram > CBOW)  
-> gensim package를 이용하여 간단하게 만들 수 있음  

-CBOW : 주변 단어를 가지고 중간단어 예측하는 법  
Score를 추출한 다음 Softmax를 취해서 각 단어가 나올 확률 계산(CrossEntropy Loss Func)  

-skip-gram : 중간단어를 가지고 주변 단어 예측하는 법  
주변 단어들에 대한 Score를 추출, sum한 다음 Backpropagation 진행  

컨텐츠 기반 모델 장단점  
-> 추천하기에 설명하기 용이  
-> 사용자가 평점을 매기지 않은 새로운 item이 들어올 경우에도 추천 가능  
-> feature를 제대로 추출하지 않으면 정확도 낮음(Domain Knowledge에 의존적임)  
-> 새로운 장르의 item을 추천하기 어려움  
-> 새로운 사용자에 대해서 좋은 추천을 하기 어려움  

### [4강] 협업 필터링  
사용자의 구매패턴이나 평점을 가지고 다른 사람들의구매패턴, 평점을 통해서 추천하는 방법  

1. 최근접 이웃기반(KNN)  
 1. User-based collaborative filtering -> 사용자의 구매패턴과 유사한 사용자를 찾아서 추천리스트 생성  
 2. Item-based collaborative filtering -> 특정 사용자가 준 점수간의 유사한 상품을 찾아서 추천 리스트 생성  
간단하고 직관적인 접근 방식, 추천한 이유를 설명가능함  
대량의 메모리, 속도 걸림, 많이 보는 아이템들이 다시 추천될 경향이 있음.  


2. 잠재 요인기반  
rating matrix에서 빈 공간을 채우기 위해서 사용자와 상품을 잘 표현하는 차원(Latent Factor)을 찾는 방법,   
행렬 분해 알고리즘 -> 사용자-아이템 상호 작용 행렬을 두 개의 저 차원 직사각형 행렬의 곱으로 분해하여 작동함.  
SVD, SGD, ALS 등등 있음  
- SGD -> User Latent, Item Latent 동시에 최적화하는 방법  
- ALS -> User Latent, Item Latent를 순차적으로 최적화하는 방법  

협업필터링 장단점  
- 도메인 지식 필요 없음  
- 사용자의 새로운 흥미 발견하기 좋음  
- 시작 단계의 모델로 선택하기 좋음(추가적인 정보가 필요하지 않음)  
- 새로운 아이템에 대해서 다루기가 힘듦 - (새로 학습)  
- side features(고객의 개인정보, 아이템의 추가정보)를 포함시키기 어려움  


### [5강] 평가함수  
추천 모델이 얼마나 잘 추천하고 있는지 객관적인 평가를 도와주기 때문임  
도메인과 목적에 따라 평가함수를 다르게 설정해야함  
1. Accuracy  
추천해준 item을 선택했냐 vs 안했냐  
- F1-score  
- MAP: 추천순서에 따라서 결과가 차이가남 상위 k개의 추천에 대해서만 평가하기 때문에 k를 바꿔가면서 나온 결광 따라 결정할 수 있음.  
-NDCG: 검색 알고리즘에서 성과를 측정하는 평가 메트릭  
	CG, DCG를 먼저 이해해야함  
	NDCG = DCG / iDCG(이상적인 DCG) -> 높으면 높을 수록 좋은 평가지표이다.  


