## 추천 시스템 입문 강의 내용 정리 및 공부  
#### 참고
- T academy (https://tacademy.skplanet.com/)  
- Recommender System KR(https://www.facebook.com/groups/2611614312273351)  
- 발표 연사자 github (https://github.com/choco9966/T-academy-Recommendation)  
- 케글 (https://www.kaggle.com/chocozzz/t-academy-recommendation2)  
- 참고 사이트 (https://bab2min.tistory.com/566)

#### 사용 데이터
- https://www.kaggle.com/zygmunt/goodbooks-10k  

### [1강] 추천 시스템 이해  

사용자에게 흥미로울 만한 상품을 제안하는 도구 기술  
-> 목표 : 어떤 사용자에게 어떤 상품을 어떻게 추천할지에  
인터넷 발전 --> 롱테일의 법칙 > 파레토의 법칙  

1. 연관분석  
-> 상품과 상품사이에 어떤 연관이 있는지 찾는 알고리즘  
1) 얼마나 같이 구매가 되는가  
2) A를 구매한 사람이 B를 구매하는가?  
평가지표 : support(지지도), lift(향상도), confidence(신뢰도)  
상품이 많을 경우 경우의수가 너무 많아짐(메모리 증가)  

2. Apriori 알고리즘  
-> 아이템셋의 증가를 줄이기 위한 방법  
진행방법  
- 단일항목집단에서 최소 지지도 이상의 항목을 선택  
- k개의 집단을 계속 만들어서 반복  
장점: 이해할 수 있음(결과에 대해서)  
단점: 연산량 많음, 속도 느림(인과관계 해석의 한계)  

3. FP-Growth 알고리즘  
Apriori 알고리즘 속도 한계 해결  
설계가 어려움, 지지도 계산이 FP-Tree를 만들고 나서 가능함  

### [2강] 컨텐츠 기반 모델 (TF-IDF 설명)  
아이템을 벡터 형태로 표현 -> 벡터들간의 유사도를 계산 후 추출  

유사도 함수  
-유클리디안 유사도(문서간의 유사도를 계산)  
= 1 / (유클리디안 거리 + 1e-05(=eps))  
계산하기 쉽지만, 두 아이템의 분포가 다르거나 범위가 다른 경우 상관성 놓치기 쉬움  

- 코사인 유사도  
문서간의 유사도를 계산  
theta값을 가지고 유사도를 계산  
벡터의 크기가 중요하지 않은 경우에 많이 사용  

- 피어슨 유사도  
- 자카드 유사도(집합간의 결합관련)  

-> 도메인에 따른 유사도 계산을 해야함  

알고리즘: TF-IDF(텍스트 기반일 경우)  
TF-IDF를 사용하는 이유  
-> 의미없지만 많이 반복되는 단어들을 페널티를 주어 의미있는 단어들이 부각되게 하는 법  
직관적인 해석이 가능하지만 sparse 행렬이 될 확률이 많다. **(메모리 많이 잡아먹음)**  

### [3강] 컨텐츠 기반 모델 (Word2Vec 설명)
통계기반의 방법 단점  
-> 대규모 말뭉치는 메모리상의 문제가 발생(sparse형태이기 때문)  

해결책
Word2Vec - 단어간 유사도를 반영하여 단어를 벡터로 변환 (성능 : skip-gram > CBOW)  
-> gensim package를 이용하여 간단하게 만들 수 있음  

-CBOW : 주변 단어를 가지고 중간단어 예측하는 법  
Score를 추출한 다음 Softmax를 취해서 각 단어가 나올 확률 계산(CrossEntropy Loss Func)  

-skip-gram : 중간단어를 가지고 주변 단어 예측하는 법  
주변 단어들에 대한 Score를 추출, sum한 다음 Backpropagation 진행  

컨텐츠 기반 모델 장단점  
-> 추천하기에 설명하기 용이  
-> 사용자가 평점을 매기지 않은 새로운 item이 들어올 경우에도 추천 가능  
-> feature를 제대로 추출하지 않으면 정확도 낮음(Domain Knowledge에 의존적임)  
-> 새로운 장르의 item을 추천하기 어려움  
-> 새로운 사용자에 대해서 좋은 추천을 하기 어려움  

 
